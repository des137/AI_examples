{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8fdaaf-1c8a-42c6-aae5-22cd14edd886",
   "metadata": {},
   "source": [
    "# IBM Quantum Computing RAG on IBM Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bb0a0b-5b3e-4faf-a044-d68baa89af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deshmukh/miniconda3/envs/watsom_llm_dec25/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var, wrap_text\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "from langchain_milvus import Milvus\n",
    "import tempfile\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n",
    "from docling_core.types.doc.labels import DocItemLabel\n",
    "from langchain_core.documents import Document\n",
    "# from torch.optim.lr_scheduler import LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d938d0bd-15f4-4c4d-89fb-d22b670d976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WATSONX_APIKEY = get_env_var('WATSONX_APIKEY')\n",
    "\n",
    "WATSONX_PROJECT_ID = get_env_var('WATSONX_PROJECT_ID')\n",
    "\n",
    "URL = get_env_var(\"WATSONX_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f878ed33-823b-4ac3-aadc-73628b113e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b3a7fd-fd39-4691-8435-c9be9b95e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 12:54:56,214 - INFO - Use pytorch device_name: mps\n",
      "2025-12-01 12:54:56,215 - INFO - Load pretrained SentenceTransformer: ibm-granite/granite-embedding-30m-english\n"
     ]
    }
   ],
   "source": [
    "embeddings_model_path = \"ibm-granite/granite-embedding-30m-english\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embeddings_model_path,\n",
    ")\n",
    "embeddings_tokenizer = AutoTokenizer.from_pretrained(embeddings_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538e4e78-518c-4cb6-b084-14aadf27a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector database will be saved to /var/folders/rh/41xw7p5x5xn6nc78sc2h6__40000gn/T/milvus_98k348df.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deshmukh/miniconda3/envs/watsom_llm_dec25/lib/python3.12/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "db_file = tempfile.NamedTemporaryFile(prefix=\"milvus_\", suffix=\".db\", delete=False).name\n",
    "print(f\"The vector database will be saved to {db_file}\")\n",
    "\n",
    "vector_db = Milvus(\n",
    "    embedding_function=embedding_model,\n",
    "    connection_args={\"uri\": db_file},\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    "    index_params={\"index_type\": \"AUTOINDEX\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5a9914-97a9-4339-8306-3eab1e3c7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 12:54:59,203 - INFO - Client successfully initialized\n",
      "2025-12-01 12:54:59,960 - INFO - HTTP Request: GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-11-12&project_id=4e0a5d87-689d-41e6-9ad8-982592d431c7&filters=%21lifecycle_withdrawn&limit=200 \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 12:54:59,971 - INFO - Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-11-12&project_id=4e0a5d87-689d-41e6-9ad8-982592d431c7&filters=%21lifecycle_withdrawn&limit=200'\n"
     ]
    }
   ],
   "source": [
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-4-h-small\",\n",
    "    apikey=WATSONX_APIKEY,\n",
    "    url=URL,\n",
    "    project_id=WATSONX_PROJECT_ID,\n",
    "    params={\n",
    "        \"temperature\": 0,\n",
    "        \"max_new_tokens\": 512,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3beea4c-4c41-413a-bd4a-1ee083ad73cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:00:11,524 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-01 13:00:11,543 - INFO - Going to convert document batch...\n",
      "2025-12-01 13:00:11,544 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-01 13:00:11,545 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-12-01 13:00:11,546 - INFO - Accelerator device: 'mps'\n",
      "2025-12-01 13:00:12,298 - INFO - Accelerator device: 'mps'\n",
      "2025-12-01 13:00:12,734 - INFO - Processing document 2506.03094v1.pdf\n",
      "2025-12-01 13:00:29,546 - INFO - Finished converting document 2506.03094v1.pdf in 18.42 sec.\n",
      "2025-12-01 13:00:30,454 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-01 13:00:30,466 - INFO - Going to convert document batch...\n",
      "2025-12-01 13:00:30,467 - INFO - Processing document 2511.19983v1.pdf\n",
      "2025-12-01 13:00:37,431 - INFO - Finished converting document 2511.19983v1.pdf in 7.22 sec.\n",
      "2025-12-01 13:00:38,135 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-01 13:00:38,145 - INFO - Going to convert document batch...\n",
      "2025-12-01 13:00:38,146 - INFO - Processing document 2303.09491v1.pdf\n",
      "2025-12-01 13:00:41,310 - INFO - Finished converting document 2303.09491v1.pdf in 3.46 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 document chunks created\n"
     ]
    }
   ],
   "source": [
    "# Here are our documents, feel free to add more documents in formats that Docling supports\n",
    "sources = [\n",
    "    'https://arxiv.org/pdf/2506.03094', \n",
    "    'https://arxiv.org/pdf/2511.19983', \n",
    "    'https://arxiv.org/pdf/2303.09491'    \n",
    "]\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert and chunk out documents\n",
    "doc_id = 0\n",
    "texts: list[Document] = [\n",
    "    Document(page_content=chunk.text, metadata={\"doc_id\": (doc_id:=doc_id+1), \"source\": source})\n",
    "    for source in sources\n",
    "    for chunk in HybridChunker(tokenizer=embeddings_tokenizer).chunk(converter.convert(source=source).document)\n",
    "    if any(filter(lambda c: c.label in [DocItemLabel.TEXT, DocItemLabel.PARAGRAPH], iter(chunk.meta.doc_items)))\n",
    "]\n",
    "\n",
    "print(f\"{len(texts)} document chunks created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f27a9042-e9d0-4302-9cd0-2fa6909ee303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 documents added to the vector database\n"
     ]
    }
   ],
   "source": [
    "ids = vector_db.add_documents(texts)\n",
    "print(f\"{len(ids)} documents added to the vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b54c2206-702f-4398-950b-f633806946ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 source documents returned\n",
      "page_content='In practice, QML is a broad term that encompasses all of the tasks shown in Fig. 1. For example, one can apply machine learning to quantum applications like discovering quantum algorithms [8] or optimizing quantum experiments [9, 10], or one can use a quantum neural network to process either classical or quantum information [11]. Even classical tasks can be viewed as QML when they are quantum inspired [12]. We note that the focus of this article will be on quantum neural networks, quantum deep learning, and quantum kernels, even though the field of QML is quite broad and goes beyond these topics.\n",
      "After the invention of the laser, it was called a solution in search of a problem. To some degree, the situation with QML is similar. The complete list of applications of QML is not fully known. Nevertheless, it is possible to speculate that all the areas shown in Fig. 2 will be impacted by QML. For example, QML will likely benefit chemistry, materials science, sensing and metrology, classical data analysis, quantum error correction, and quantum algorithm design. Some of these applications produce data that is inherently quantum mechanical, and hence it is natural to apply QML (rather than classical ML) to them.\n",
      "While there are similarities between classical and quantum ML, there are also some differences. Because QML employs quantum computers, noise from these computers can be a major issue. This includes hardware noise like decoherence as well as statistical noise (i.e., shot noise) that arises from measurements on quantum states. Both\n",
      "FIG. 1. Quantum Machine Learning (QML) tasks . Quantum machine learning is usually considered for four main tasks. These include tasks where the data is either classical or quantum, and where the algorithm is either classical or quantum. Top left: tensor networks are quantum-inspired classical methods that can analyze classical data. Top right: unitary time-evolution data U from a quantum system can be classically compiled into a quantum circuit. Bottom left: handwritten digits can be mapped to quantum states for classification on a quantum computer. Bottom right: molecular ground state data can be classified directly on a quantum computer. The figure shows ground state energy E dependence on the distance d between the atoms.\n",
      "of these noise sources can complicate the QML training process. Moreover, non-linear operations (e.g., neural activation functions) that are natural in classical ML require more careful design of QML models due to the linearity of quantum transformations.' metadata={'pk': 462582459524186702, 'doc_id': 199, 'source': 'https://arxiv.org/pdf/2303.09491'}\n",
      "================================================================================\n",
      "page_content='M. Cerezo, 1, 2, 3 Guillaume Verdon, 4, 5, 6 Hsin-Yuan Huang, 7, 8 Lukasz Cincio, 9, 3 and Patrick J. Coles 10, 9, 3\n",
      "1 Information Sciences, Los Alamos National Laboratory, Los Alamos, NM 87545, USA\n",
      "2 Center for Nonlinear Studies, Los Alamos National Laboratory, Los Alamos, New Mexico 87545, USA\n",
      "3 Quantum Science Center, Oak Ridge, TN 37931, USA\n",
      "4 X, Mountain View, CA, USA\n",
      "5 Institute for Quantum Computing, University of Waterloo, ON, Canada\n",
      "6 Department of Applied Mathematics, University of Waterloo, ON, Canada\n",
      "7 Institute for Quantum Information and Matter, California Institute of Technology, USA\n",
      "8 Department of Computing and Mathematical Sciences, California Institute of Technology, USA\n",
      "9 Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico 87545, USA\n",
      "10 Normal Computing Corporation, New York, New York, USA\n",
      "At the intersection of machine learning and quantum computing, Quantum Machine Learning (QML) has the potential of accelerating data analysis, especially for quantum data, with applications for quantum materials, biochemistry, and high-energy physics. Nevertheless, challenges remain regarding the trainability of QML models. Here we review current methods and applications for QML. We highlight differences between quantum and classical machine learning, with a focus on quantum neural networks and quantum deep learning. Finally, we discuss opportunities for quantum advantage with QML.' metadata={'pk': 462582459524186700, 'doc_id': 197, 'source': 'https://arxiv.org/pdf/2303.09491'}\n",
      "================================================================================\n",
      "page_content='The recognition that the world is quantum mechanical has allowed researchers to embed well-established, but classical, theories into the framework of quantum Hilbert spaces. Shannon's information theory, which is the basis of communication technology, has been generalized to quantum Shannon theory (or quantum information theory), opening up the possibility that quantum effects could make information transmission more efficient [1]. The field of biology has been extended to quantum biology to allow for a deeper understanding of biological processes like photosynthesis, smell, and enzyme catalysis [2]. Turing's theory of universal computation has been extended to universal quantum computation [3], potentially leading to exponentially faster simulations of physical systems.\n",
      "One of the most successful technologies of this century is machine learning (ML), which aims to classify, cluster, and recognize patterns for large data sets. Learning theory has been simultaneously developed alongside of ML technology in order to understand and improve upon its success. Concepts like support vector machines, neural networks, and generative adversarial networks have impacted science and technology in profound ways. ML is now ingrained into society to such a degree that any fundamental improvement to ML leads to tremendous economic benefit.\n",
      "Like other classical theories, ML and learning theory can in fact be embedded into the quantum mechanical formalism. Formally speaking, this embedding leads to the field known as Quantum Machine Learning (QML) [4-6], which aims to understand the ultimate limits of data analysis allowed by the laws of physics. Practically speaking, the advent of quantum computers, with the hope of achieving a so-called quantum advantage (as defined below) for data analysis, is what has made\n",
      "QMLso exciting. Quantum computing exploits entanglement, superposition, and interference to perform certain tasks with significant speedups over classical computing, sometimes even exponentially faster. Indeed while such speedup has already been observed for a contrived problem [7], reaching it for data science is still uncertain even at the theoretical level, but this is one of the main goals for QML.' metadata={'pk': 462582459524186701, 'doc_id': 198, 'source': 'https://arxiv.org/pdf/2303.09491'}\n",
      "================================================================================\n",
      "page_content='Analyzing and learning from data requires a parameterized model, and many different models have been proposed for QML applications. Classical models like neural networks and tensor networks (as shown in Fig. 1) are often useful for analyzing data coming from quantum experiments. However, due to their novelty, we will focus our discussion on quantum models using quantum algorithms, where one applies the learning methodology directly at the quantum level.\n",
      "Similar to classical ML, there exists several different QML paradigms: supervised learning (task-based) [2628], unsupervised learning (data-based) [29, 30] and reinforced learning (reward-based) [31, 32]. While each of these fields is exciting and thriving on its own, supervised learning has recently received considerable attention for its potential to achieve quantum advantage [26, 33], resilience to noise [34], and good generalization properties [35-37], which makes it a strong candidate for nearterm applications. In what follows we discuss two popular QML models: quantum neural networks (QNNs) and quantum kernels, shown in Fig. 3, with a particular emphasis on QNNs as these are the primary ingredient of several supervised, unsupervised, and reinforced learning schemes.' metadata={'pk': 462582459524186706, 'doc_id': 203, 'source': 'https://arxiv.org/pdf/2303.09491'}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain to me what quantum machine learning is all about.\"\n",
    "retrieved_docs = vector_db.similarity_search(query) # return a list of documents\n",
    "print(f\"{len(retrieved_docs)} source documents returned\")\n",
    "for doc in retrieved_docs:\n",
    "    print(doc)\n",
    "    print(\"=\" * 80)  # Separator for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85daea1b-405e-456d-8a92-36b01e7f6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a Granite prompt for question-answering with the retrieved context\n",
    "prompt_template = ChatPromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "# Assemble the retrieval-augmented generation chain\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    ")\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    combine_docs_chain=combine_docs_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2fd267e-006b-4423-8233-032df5d99417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:00:47,596 - INFO - HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2025-11-12 \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 13:00:47,600 - INFO - Successfully finished chat for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2025-11-12'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "RAG Answer:\n",
      "Quantum Machine Learning (QML) is a field that combines machine learning and\n",
      "quantum computing, with the potential to accelerate data analysis, especially\n",
      "for quantum data. QML has applications in areas such as quantum materials,\n",
      "biochemistry, and high-energy physics. However, there are challenges regarding\n",
      "the trainability of QML models due to noise from quantum computers. One of the\n",
      "main goals of QML is to achieve a quantum advantage for data analysis, utilizing\n",
      "the speedup offered by quantum computing. QML models include quantum neural\n",
      "networks (QNNs) and quantum kernels, with QNNs being a primary ingredient in\n",
      "several learning schemes. The field of QML is broad and encompasses tasks such\n",
      "as discovering quantum algorithms, optimizing quantum experiments, and\n",
      "processing classical or quantum information using quantum neural networks.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "output = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(\"RAG Answer:\")\n",
    "print(wrap_text(output['answer']))\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467f1a8-b30d-4056-bb23-e72e5602244b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
